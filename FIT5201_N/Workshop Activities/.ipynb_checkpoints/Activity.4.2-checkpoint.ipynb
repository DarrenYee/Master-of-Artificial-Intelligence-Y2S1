{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 4.2. Document Clustering\n",
    "\n",
    "(last modified 30 August 2023)\n",
    "\n",
    "This laboratory activity should take around 2 hours to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "In this activity you will learn to:\n",
    "- Perform feature extraction on text based data using CountVectorizer and Term Frequency-Inverse Document Frequency\n",
    "- Perform dimensionality reduction using Principal Component Analysis to create interpretable visualisations\n",
    "- Solve the Document Clustering problem using K-Means Clustering\n",
    "- Use Normalised Mutual Information Index to measure the goodness of fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- Lecture 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Clustering\n",
    "\n",
    "In Lecture 8 we discussed the Document Clustering problem where we have a collection of n documents, which we try to group into K different clusters. We explored using Expectation Maximisation to solve this problem, which you may have to implement as part of Assignment 2. However, we also mentioned that the problem can also be solved using K-Means Clustering, which will be the focus of this activity. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering\n",
    "\n",
    "\n",
    "While we will not be implementing a KMeans clustering algorithm in this lab, it is worth understanding what objective the algorithm is trying to achieve during its' fitting process. \n",
    "\n",
    "The K-Means Clustering algorithm tries to separate the data into K clusters, such that each datapoint has minimal distance to the mean of the cluster it belongs to. For higher dimensional data, $\\mu$ is the centroid of the points in the cluster. \n",
    "\n",
    "\\begin{equation}\n",
    "\\argmin_S \\sum_{i=1}^k \\sum_{x\\in S_i} ||x - \\mu_i||^2 = \\argmin_S \\sum_{i=1}^k |S_i| Var(S_i)\n",
    "\\end{equation}\n",
    "\n",
    "Finding the optimal solution to the problem is NP-hard, so most approaches to solving this problem involve using heuristics to find approximate solutions instead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A: Aquiring Data\n",
    "\n",
    "We use a subset of a publicly available dataset called 20 Newsgroups originally published in http://qwone.com/~jason/20Newsgroups/. This dataset contains more than 18K documents covering 20 different topics. For the simplicity and reducing the execution and evaluation times, we only use ~2700 samples randomly selected from 4 categories. The filtered data is stored in `20ng-train-all-terms.txt` file.\n",
    "\n",
    "Read in the text file '20ng-train-all-terms.txt' and split the file up into individual documents and their associated label. Note that each line of the file contains a label followed by an article separated by \\t. Then, store the data in a Pandas DataFrame for ease of visualisation. Note that we will continue to use Numpy arrays for all computational processes as this is faster and more efficient than Pandas. We can cast a Pandas DataFrame to a numpy array with the .values method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "with open('20ng-train-all-terms.txt', 'r') as file:\n",
    "    text = file.readlines()\n",
    "all([length == 2 for length in [len(line.split('\\t')) for line in text]])\n",
    "labels, articles = [line.split('\\t')[0].strip() for line in text], [line.split('\\t')[1].strip() for line in text]\n",
    "docs = pd.DataFrame(data = zip(labels,articles), columns=['label', 'article'])\n",
    "docs.label = docs.label.astype('category')\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B: Feature Extraction\n",
    "At the moment each of our documents are being stored as a single, very long string. This makes doing any analysis very inconventient. Instead of using our raw data directly, we will instead perform feature extraction on the data before doing our clustering. \n",
    "\n",
    "The features should be numerical, otherwise our Euclidean distance (non-similarity) measure will not work. \n",
    "\n",
    "To do so, we use `sklearn.feature_extraction.text.CountVectorizer` to tailor the texts and calculate word counts (frequency of each word in each single document) as the features.\n",
    "\n",
    "Use the CountVectorizer to exctract features from the data. The min_df parameter controls the minimum number of times a word needs to be featured in the text before it is added to the feature space. Find a value for this feature that you feel is appropriate and justify your choice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "min_freq = 10\n",
    "feature_options = []\n",
    "for i in range(min_freq):\n",
    "    ### YOUR CODE HERE ###\n",
    "    cv = \n",
    "\n",
    "    ### END YOUR CODE HERE ###\n",
    "    features = cv.fit_transform(raw_documents=articles)\n",
    "    feature_options += [features]\n",
    "    print(len(cv.get_feature_names_out()))\n",
    "\n",
    "# features = feature_options[] # Which option should we choose?\n",
    "# features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task C: Document Clustering with Kmeans\n",
    "\n",
    "Implement an sklearn pipeline which takes as input raw text data, performs feature extraction using CountVectorizer and then fits the data using KMeans. Use the min_freq value you selected in Task B and assume we know the real number of clusters (4 newsgroups). Use this pipeline to fit the raw articles data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "### YOUR CODE HERE ###\n",
    "cv = \n",
    "km = \n",
    "pipe = \n",
    "### END YOUR CODE HERE ###\n",
    "pipe.fit\n",
    "\n",
    "pipe.fit(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task D: Principal Component Analysis and Visualization\n",
    "Recal that our feature space is a high-dimensional one and we cannot plot all the dimensions. \n",
    "\n",
    "Principal Component Analysis is an algorithm that transforms our data into a new coordinate system. This new coordinate system is constructed such that features are ordered in decending order of how much of the variance in the data they explain. \n",
    "\n",
    "PCA is often commonly used technique for dimensionality reduction, as we can often discard all but a few of the most highly ranked features and still maintain much of the data's explanatory power. \n",
    "\n",
    "Use sklearn.decomposition.PCA to perform a PCA, extracting only first two principle components (components with the largest eigenvalues), then use these components to plot a lower dimensional represenation of our data. \n",
    "\n",
    "**Note:** The color codes can be very different in these plots as the cluster orders, and hence their labels and colors, can be very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## perform pca\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "pca = \n",
    "_2D_features = \n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "## plot the kmeans outcome\n",
    "_, axs = plt.subplots(1, 2, figsize=(12, 8), tight_layout=True)\n",
    "axs[0].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=km.labels_)\n",
    "axs[0].set_title('KMeans labels on count features')\n",
    "\n",
    "\n",
    "## plot the original data\n",
    "axs[1].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=docs.label.cat.codes)\n",
    "axs[1].set_title('True Labels on count features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task E: A Simple Normalization\n",
    "As the above figures, in some cases the data samples are located far from each other, while in some other cases, they are colocated. Also note that the scale of PCs can be very different. This suggests that with a normalization we might get better result as the performance of Kmeans is very sensitive to the distance between the points.\n",
    "\n",
    "Use sklearn.preprocessing.Normalizer to normalise the data using the l2 norm and then refit KMeans on the newly normalised data. \n",
    "This can all be incorporated into a single pipeline that perorms feature extraction using CountVectorizer, then normalises the data using Normalizer then fits using KMeans. \n",
    "\n",
    "Finally, perform a 2 component PCA again, plot the results and compare them to the ones in the above plot. Has the fit improved? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise by dividing each feature row by its L2 norm\n",
    "from sklearn.preprocessing import Normalizer\n",
    "### YOUR CODE HERE ###\n",
    "l2_norm = \n",
    "features_normalised = \n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "features_normalised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "### YOUR CODE HERE ###\n",
    "cv = \n",
    "l2_norm =\n",
    "km = \n",
    "pipe = \n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "pipe.fit(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform pca\n",
    "### YOUR CODE HERE ###\n",
    "pca = \n",
    "_2D_features = \n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "## plot the kmeans outcome\n",
    "_, axs = plt.subplots(1, 2, figsize=(12, 8), tight_layout=True)\n",
    "axs[0].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=km.labels_)\n",
    "axs[0].set_title('KMeans labels on normalised count features')\n",
    "\n",
    "\n",
    "## plot the original data\n",
    "axs[1].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=docs.label.cat.codes)\n",
    "axs[1].set_title('True Labels on normalised count features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task F: A More Advanced Set of Features\n",
    "\n",
    "The simple normalization improved Kmeans outcome, but not that much. This suggests that not only the initialization and number of clusters have great impact on the kmeans outcome, but the feature space itself should be discriminative as well. In the followings, we try another feature (instead of the simple word counts) that is knonw as Term Frequency-Inverse Document Frequency (TFIDF). In its core, TFIDF in nothing but weighted word count.\n",
    "\n",
    "Let's calculate TFIDF feature values and then repeat the above experimetns. Implement another pipeline that performs feature extraction using TFIDF and then fits using KMeans. Note that we do not need to explictly include a normaliser in the pipeline as TfidfVectorizer can perform the normalisation itself if we set the norm argument. \n",
    "\n",
    "Perform another 2 component PCA again, plot the results and compare them to the ones in the above plot. Has the fit improved? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "### YOUR CODE HERE ###\n",
    "tfidf = \n",
    "features = \n",
    "km = \n",
    "pipe = \n",
    "### END YOUR CODE HERE ###\n",
    "pipe.fit(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform pca\n",
    "### YOUR CODE HERE ###\n",
    "pca = \n",
    "_2D_features = \n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "## plot the kmeans outcome\n",
    "_, axs = plt.subplots(1, 2, figsize=(12, 8), tight_layout=True)\n",
    "axs[0].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=km.labels_)\n",
    "axs[0].set_title('KMeans labels on TFIDF features')\n",
    "\n",
    "\n",
    "## plot the original data\n",
    "axs[1].scatter(x=_2D_features[:,0],y=_2D_features[:,1], c=docs.label.cat.codes)\n",
    "axs[1].set_title('True Labels on TFIDF features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task G: Model Evaluation\n",
    "\n",
    "To evaluate the alignment between our cluster predictions and the ground truth labels, we use a clustering evaluation metric such as normalised mutual information index. Note that we can not use a metric like `accuracy` because there is no guarantee that our cluster ids are aligned with our class label ids so instead we use a measure of mutual information such as NMI. (See [this source](https://towardsdatascience.com/7-evaluation-metrics-for-clustering-algorithms-bdc537ff54d2#ebd4) for more information).\n",
    "\n",
    "Based on the NMI scores below, do you have a feel for which feature creation method is better for this dataset? How confident do you feel about this statement? What could you do to make yourself more certain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test = train_test_split(docs, test_size=0.2, random_state=123)\n",
    "X_train, y_train = docs_train.article.values, docs_train.label.cat.codes\n",
    "X_test, y_test = docs_test.article.values, docs_test.label.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(lowercase=True,\n",
    "                     stop_words='english',\n",
    "                     min_df=5, )\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=True,\n",
    "                     stop_words='english',\n",
    "                     min_df=5,\n",
    "                    norm='l2')\n",
    "\n",
    "l2_norm = Normalizer(norm='l2')\n",
    "\n",
    "km = KMeans(n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3319044284043788, 0.31434932132520044)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cv = make_pipeline(cv, l2_norm, km)\n",
    "pipe_cv.fit(X_train)\n",
    "\n",
    "NMI(pipe_cv.predict(X_train), y_train), NMI(pipe_cv.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/.local/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42857913067313197, 0.4232697524531802)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf = make_pipeline(tfidf, km)\n",
    "pipe_tfidf.fit(X_train)\n",
    "\n",
    "NMI(pipe_tfidf.predict(X_train), y_train), NMI(pipe_tfidf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task H: Learning Curve\n",
    "\n",
    "Let us examine our conclusion from Task G by repeating the experiment many times, across many different dataset sizes. \n",
    "\n",
    "Complete the code in the cell below to generate the results necessary to plot a learning curve over the train size, comparing CountVectorizer and TfidfVectorizer as a method for creating features from our raw data. \n",
    "\n",
    "We will only perform 10 repetitions on 10 train sizes as this will already take around 5 minutes to run on most laptops.\n",
    "\n",
    "After this, compute the mean and the size of the 1.96 standard error bar from res_array and use this to plot an errorbar comparing our two methods. Do these results align with what we saw in Task G? How confident are you in these results? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Activity4 import BootstrapSplitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_sizes = np.logspace(start=0.8, stop=0.99, num=10, base=len(articles))/len(articles)\n",
    "reps = 10\n",
    "\n",
    "cv = CountVectorizer(lowercase=True,\n",
    "                     stop_words='english',\n",
    "                     min_df=5, )\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=True,\n",
    "                     stop_words='english',\n",
    "                     min_df=5,\n",
    "                    norm='l2')\n",
    "\n",
    "l2_norm = Normalizer(norm='l2')\n",
    "\n",
    "km = KMeans(n_clusters=4)\n",
    "\n",
    "res_array = np.zeros(shape=(4, len(train_sizes), reps))\n",
    "for i, train_size in enumerate(train_sizes):\n",
    "    print('N_{0}={1}: rep='.format(i, int(train_size*len(articles))), end='')\n",
    "    splitter = BootstrapSplitter(reps=reps, train_size=train_size, random_state=0)\n",
    "    for j, (train_idx, test_idx) in enumerate(splitter.split(articles)):\n",
    "        print('{0}'.format(j), end=', ')\n",
    "        ### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        ### END YOUR CODE HERE ###\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "mus = \n",
    "stes = \n",
    "axs.errorbar # train NMI for CV\n",
    "axs.errorbar # test NMI for CV\n",
    "axs.errorbar # train NMI for tfidf\n",
    "axs.errorbar # test NMI for tfidf\n",
    "### END YOUR CODE HERE ###\n",
    "\n",
    "axs.set_xlabel('Train Size', size=15)\n",
    "axs.set_ylabel('NMI', size=15)\n",
    "axs.set_title('Model Comparison', size=15)\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussions:\n",
    "1- We knew that KMeans is very sensitive to its initialzation (initial cluster centers) and number of clusters (`k`). Apart from that, what is the other main limitation of Kmeans algorithm (**Hint:** Think of features set and distance metric)?\n",
    "\n",
    "2- Given the limitaitons we encounter in the previous questions, what could be the remedy (**Hint:** Think of EM techniques that are covered in the previous chapter)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
