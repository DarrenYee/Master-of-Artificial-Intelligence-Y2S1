{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 2.1. Linear Regression\n",
    "Last modified (9 Aug 2023)\n",
    "\n",
    "### Learning Outcomes\n",
    "\n",
    "In this activity we learn to:\n",
    "\n",
    "- evaluate machine learning algorithm with synthetic data\n",
    "- find optimal parameters for linear models directly by solving the normal equations\n",
    "- describe and implement gradient descent and stochastic gradient\n",
    "- describe the effect of the (stochastic) gradient parameters learning rate and batch size\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Activity 1\n",
    "- Lecture 3\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this activity we will implement and evaluate different algorithms to fit the parameter vector $\\mathbf{w} \\in \\mathbb{R}^p$ of a linear regression model with predictions\n",
    "\\begin{equation*}\n",
    "y(\\mathbf{x}, \\mathbf{w}) = \\boldsymbol{\\phi}(\\mathbf{x})\\cdot \\mathbf{w}\n",
    "\\end{equation*}\n",
    "given training data $(\\mathbf{x}_1, t_1), \\dots, (\\mathbf{x}_N, t_N) \\in \\mathbb{R}^M \\times \\mathbb{R}$ and some choice of **basis function** expansion $\\boldsymbol{\\phi}(\\mathbf{x})=(\\phi_1(\\mathbf{x}), \\dots, \\phi_p(\\mathbf{x}))$. To keep things simple, we will only consider linear basis functions here (while keeping the notation general).\n",
    "\n",
    "All our algorithms will approach the model fitting problem by minimising the **mean (or sum) of squared errors**\n",
    "\\begin{align*}\n",
    "E(\\mathbf{w}) &= \\frac{1}{2n} \\sum_{n=1}^N (t_n - y(\\mathbf{x_n}, \\mathbf{w}))^2 \\\\\n",
    "&= \\frac{1}{2n} \\|\\mathbf{t} - \\boldsymbol{\\Phi}\\mathbf{w} \\|^2\n",
    "\\end{align*}\n",
    "where in the last form we have made use of the compact matrix/vector notation introduced in the lecture with target vector $\\mathbf{t}=(t_1, \\dots, t_N)$ and feature matrix $\\boldsymbol{\\Phi}$ that contains the feature expansions $\\boldsymbol{\\phi}(\\mathbf{x_n})$ as rows.\n",
    "\n",
    "### Outline\n",
    "\n",
    "We will first define a test problem based on synthetic data and then implement and evaluate the following three fitting strategies:\n",
    "\n",
    "1. First, we will implement the direct solution to optimising $E(\\mathbf{w})$ by deriving the gradient of the objective function and, by setting it to the zero vector, obtain a sytem of linear equations (called the **normal equations**) that describe the optimal weights.\n",
    "2. Then we use the gradient in a different way to define an iterative solver called **gradient descent** (GD). While this intermediate step is not particularly useful for linear models it is a very important to machine learning in general, because, in contrast to the first approach, it easily generalises to more complicated models.\n",
    "3. Finally, we modify GD to only use approximate random gradients. The resulting **stochastic gradient descient** (SGD) variant, is not only easily generalisable to other models but can also be highly efficient for large sets of training data. \n",
    "\n",
    "In Activity 2.2, we will then move from ordinary least squares regression to regularised variants."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## A Synthetic Test Case\n",
    "\n",
    "In addition to using real-world test cases for evaluating machine learning algorithms, one also often defines a **synthetic data generator**, i.e., a procedure that can be used to sample arbitrary amounts of data with known properties. Some advantage of this approach are that\n",
    "\n",
    "1. We can evaluate the performance of the algorithm for any desired size of training data.\n",
    "2. We can estimate the expected performance of the fitted model on unseen data to arbitrary precision because we can sample as many test data points as we like.\n",
    "3. Even better, in addition to approximating the expected error on unseen data, we can directly investigate how well the fitted model parameters describe the data generator.\n",
    "\n",
    "To illustrate the third point, let us go ahead and define our generator. We will implement a process that yields data points $(\\mathbf{x}, t)$ such that\n",
    "\\begin{equation*}\n",
    "t = \\mathbf{x} \\cdot \\mathbf{w}^* + \\epsilon\n",
    "\\end{equation*}\n",
    "where $\\epsilon \\sim N(0, \\sigma^2)$ is normally distributed noise with standard deviation $\\sigma$ and $\\mathbf{x}$ is drawn from some multivariate normal distribution (we will not be concerned too much with the distribution of $\\mathbf{x}$ here, but have to specify it for the sake of completeness). With this process we can then evaluate a linear model in terms of how well the fitted weights $\\mathbf{w}$ resemble the true (and optimal) weights $\\mathbf{w}^*$.\n",
    "\n",
    "Below, we implement the data generator for some general choice of **optimal weight** vector $\\mathbf{w}^*$. Afterwards we will use the specific choice of \n",
    "$$\\mathbf{w}^*=(-5, -3, 4, 5, 10)$$ \n",
    "as concrete example throughout this notebook. In particular, we will use the convention that the last element of $\\mathbf{x}$ is set to the constant $1$, which allows us to fit a constant intercept term without further special treatment.\n",
    "\n",
    "To sample the random part of the input vector and the noise variable $\\epsilon$, we will use `multivariate_normal` and `norm` from the `scipy.stats` module. This module implements a wide range of statistical distributions, for which one can use the method `rvs` to sample random observations.\n",
    "\n",
    "#### Task A: Complete the Data Generator\n",
    "\n",
    "Complete the line below by setting epsilon to be a vector with random components sampled from the prescribed normal distribution for the noise component. \n",
    "\n",
    "Hint: Use [`scipy.stats.norm`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html) (method `rvs`) with an appropriate choice of size (number of observations), location (mean), and scale (standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.        ,  0.12573022, -0.13210486,  0.64042265,  0.10490012],\n",
       "        [ 1.        , -0.53566937,  0.36159505,  1.30400005,  0.94708096],\n",
       "        [ 1.        , -0.70373524, -1.26542147, -0.62327446,  0.04132598],\n",
       "        [ 1.        , -2.32503077, -0.21879166, -1.24591095, -0.73226735],\n",
       "        [ 1.        , -0.54425898, -0.31630016,  0.41163054,  1.04251337],\n",
       "        [ 1.        , -0.12853466,  1.36646347, -0.66519467,  0.35151007],\n",
       "        [ 1.        ,  0.90347018,  0.0940123 , -0.74349925, -0.92172538],\n",
       "        [ 1.        , -0.45772583,  0.22019512, -1.00961818, -0.20917557],\n",
       "        [ 1.        , -0.15922501,  0.54084558,  0.21465912,  0.35537271],\n",
       "        [ 1.        , -0.65382861, -0.12961363,  0.78397547,  1.49343115]]),\n",
       " array([ -1.47582307,  13.54012143, -11.23778022, -11.27761315,\n",
       "          8.92788369,   1.11355145, -19.34855739,  -9.58100799,\n",
       "          2.44271553,  16.26517689]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "def make_linear_data(n_samples, weights, noise=1, feature_mean = None, feature_cov = None, random_state=None):\n",
    "    RNG = np.random.default_rng(seed=random_state)\n",
    "    p = len(weights)\n",
    "\n",
    "    # generate feature matrix\n",
    "    feature_mean = np.zeros(p-1) if feature_mean is None else feature_mean\n",
    "    feature_cov = np.eye(p-1) if feature_cov is None else feature_cov\n",
    "    x = multivariate_normal.rvs(feature_mean, feature_cov, size=n_samples, random_state=RNG)\n",
    "    x = np.hstack((np.ones(shape=(n_samples, 1)), x))\n",
    "\n",
    "    # generate target vector\n",
    "    epsilon = norm.rvs (loc  = 0, size = n_samples, scale = 1)\n",
    "    t = x.dot(weights) + epsilon\n",
    "    \n",
    "    return x, t\n",
    "\n",
    "weights_true = np.array([-5, -3, 4, 5, 10])\n",
    "make_linear_data(10, weights=weights_true, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Solution via Normal Equations\n",
    "\n",
    "All our algorithms are based on understanding the gradient of the mean squared error function\n",
    "\\begin{equation*}\n",
    "E(\\mathbf{w}) = \\frac{1}{2n} \\|\\mathbf{t} - \\boldsymbol{\\Phi}\\mathbf{w} \\|^2\n",
    "\\end{equation*}\n",
    "that, as we saw in the lecture, is given as \n",
    "\\begin{equation*}\n",
    "\\nabla E(\\mathbf{w}) = \\frac{1}{n} \\Phi^T(\\Phi \\mathbf{w} - \\mathbf{t}) \\enspace .\n",
    "\\end{equation*}\n",
    "By setting this expression to the zero-vector and re-arranging, we derived that the weights that minimise the mean squared error can be found by solving the **normal equations**:\n",
    "\\begin{equation*}\n",
    "\\Phi^T\\Phi \\mathbf{w} = \\Phi^T \\mathbf{t} \\enspace .\n",
    "\\end{equation*}\n",
    "By accessing solvers for systems of linear equations, we can thus implement a first fitting algorithm very easily. Specifically in `numpy` we have the package [`numpy.linalg`](https://numpy.org/devdocs/reference/routines.linalg.html) for that.\n",
    "\n",
    "#### Task B: Implement Normal Equations\n",
    "\n",
    "Complete the line in the implementation of the linear model below that use [`numpy.linalg.solve`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html) to solve the normal equations.\n",
    "\n",
    "**Hint**: To set up the system of linear equations of the form $Ax=b$ for a matrix $A$ and a vector $b$, you to compute its left-hand-side (lhs) $A$ and right-hand-side (rhs) $b$. To do that for the normal equations you need to be able to:\n",
    "\n",
    "- form the transpose of a matrix (see [ndarray.T](https://numpy.org/devdocs/reference/generated/numpy.ndarray.T.html))\n",
    "- perform matrix multiplication (of which matrix/vector multiplication is a special case) (see the functions [`dot`](https://numpy.org/devdocs/reference/generated/numpy.dot.html) and [`matmul`](https://numpy.org/devdocs/reference/generated/numpy.matmul.html#numpy.matmul))\n",
    "\n",
    "Note that `matmul` is also available via the operator `@` and `dot` is also available as a method of `ndarray` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectLinearRegressor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # set up normal equations\n",
    "        # here x is the feature matrix Phi and y is the target vector t\n",
    "        rhs = np.matmul(x.T, y)  \n",
    "        lhs = np.matmul(x.T, x)  \n",
    "\n",
    "        # find optimal weights w (coefficients) by solving system\n",
    "        self.coef_ = np.linalg.solve(lhs, rhs)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x.dot(self.coef_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this approach by generating some training data and running the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.94624365, -3.19377222,  4.07907044,  5.01837179,  9.98265357])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = make_linear_data(100, weights=weights_true, random_state=1)\n",
    "\n",
    "direct = DirectLinearRegressor().fit(x_train, y_train)\n",
    "direct.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, already with 100 training data points, our learned weight vector is very close to the true weight vector in the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(weights_true - direct.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, y_hat):\n",
    "    return ((y-y_hat)**2).mean()/2\n",
    "\n",
    "x_test, y_test = make_linear_data(100000, weights=weights_true, random_state=2)\n",
    "\n",
    "mean_squared_error(y_train, direct.predict(x_train)), mean_squared_error(y_test, direct.predict(x_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C: How good is the learned model?\n",
    "\n",
    "**Explain in one paragraph how good you think is the expected error of the learned weight vector. How much do you think can it be improved (hint: what is the best possible weight vector)? Why? You can add one small computation in the next cell to test your analysis.**\n",
    "\n",
    "*[YOUR ANSWER HERE]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, x_test.dot(weights_true))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Fitting model parameters via solving a system of linear equations is a great approach whenever this is possible. However, outside of linear regression models (with the squared error function), the optimal solution is usually not described by a linear system. This motivates studying a more general algorithm that is also based on the gradient of the error function. Just instead of setting the gradient to zero and solving for $\\mathbf{w}$, we now use the following iterative approach: \n",
    "\n",
    "- We start with an initial guess of the best weights, say $\\mathbf{w}_0=\\boldsymbol{0}$, and then \n",
    "- iteratively update our current guess by moving some distance along the negative gradient of the error function evaluated at that current guess. Formally, we set for $\\tau=1, 2, \\dots$\n",
    "\\begin{equation*}\n",
    "\\mathbf{w}_{\\tau} = \\mathbf{w}_{\\tau-1} - \\eta \\nabla E(\\mathbf{w}_{\\tau-1})\n",
    "\\end{equation*}\n",
    "- until the weights do not change any more substantially captured by the convergence criterion $\\|\\mathbf{w}_\\tau - \\mathbf{w}_{\\tau-1}\\| \\leq \\epsilon$ for some small positive **convergence threshold** $\\epsilon$.\n",
    "\n",
    "In the above update rule, $\\eta$ is a small positive parameter called the **learning rate**. As a final parameter to the method we introduce $\\tau_\\mathrm{max}$ is large positive integer that gives an upper bound on how many iterations we will perform (we hope that the convergence criterion is already satisfied much earlier). \n",
    "\n",
    "The above strategy is motivated by the fact the negative gradient defines the update direction of steepest descent of the error function. Indeed, we know that, if the learning rate is not too large, the updated weights will have a smaller value than the current weights. What can we say about the limit of the weight sequence generated by our algorithm?\n",
    "\n",
    "#### Task D: Explain Convergence of Gradient Descent\n",
    "\n",
    "**Give an argument why the weight sequence generated by gradient descent must converge to the same optimal solution found by the direct method (for small enough $\\eta$). Hint: remember the characterisation of the optimal solution by the gradient used for the direct method.**\n",
    "\n",
    "*[YOUR ANSWER HERE]*\n",
    "\n",
    "#### Task E: Implement Gradient Descent\n",
    "\n",
    "**Complete the implementation below by adding one or two lines that compute the gradient of the error function at the current weight vector and then compute the update rule for the new weights. Note that in this implementation we store all the whole weight sequence in a large matrix to be able to visualise the workings of the algorithm afterwards.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDLinearRegressor:\n",
    "\n",
    "    def __init__(self, eta=0.01, tau_max=1000, epsilon=0.00001):\n",
    "        self.eta = eta\n",
    "        self.tau_max = tau_max\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        # initial weight matrix with p columns and as many rows as we can have iterations\n",
    "        # we will store each intermediate weight vector in one row of this matrix\n",
    "        n, p = x.shape\n",
    "        self.w_ = np.zeros(shape=(self.tau_max+1, p))\n",
    "\n",
    "        for tau in range(1, self.tau_max+1):\n",
    "            grad = # YOUR CODE HERE FOR COMPUTING GRADIENT (previous weights are in self.w_[tau-1])\n",
    "            self.w_[tau] = # YOUR CODE HERE FOR COMPUTING NEW WEIGHTS\n",
    "            # stopping criterion\n",
    "            if np.linalg.norm(self.w_[tau]-self.w_[tau-1]) < self.epsilon:\n",
    "                break\n",
    "\n",
    "        # set final coefficients\n",
    "        self.coef_ = self.w_[tau] \n",
    "        # delete unused rows from weight matrix\n",
    "        self.w_ = self.w_[:tau+1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x.dot(self.coef_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us test the implementation on the previously generated training data and investigate the produced weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = GDLinearRegressor(eta=0.5, tau_max=10000).fit(x_train, y_train)\n",
    "gd.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, those look extremely close to the optimal weights obtained by the closed form solution (which in turn were very close to the true weights). Let us compute just how close they are and the plot the weight sequence against the values of the direct solution plus the development of the train and test error across all iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(gd.coef_-direct.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_weight_sequences(w, w_opt, ax):\n",
    "    p = len(w_opt)\n",
    "    for j in range(p):\n",
    "        lines = ax.plot(w[:, j], label=f'$w_{j}$', zorder=2)\n",
    "        ax.axhline(w_opt[j], linestyle='--', alpha=0.4, color=lines[0].get_color())\n",
    "    ax.legend()\n",
    "    ax.margins(x=0)\n",
    "    ax.set_xlabel(r'$\\tau$')\n",
    "    ax.set_ylabel('$w$')\n",
    "\n",
    "def plot_errors(w, x_train, y_train, x_test, y_test, ax):\n",
    "    train_risk = ((x_train.dot(w.T).T - y_train.T)**2).mean(axis=1)/2\n",
    "    test_risk = ((x_test.dot(w.T).T - y_test.T)**2).mean(axis=1)/2\n",
    "    ax.plot(train_risk, label='train')\n",
    "    ax.plot(test_risk, label='test')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r'$\\tau$')\n",
    "    ax.set_ylabel('$E(w)$')\n",
    "    ax.margins(x=0)\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "plot_weight_sequences(gd.w_, direct.coef_, axs[0])\n",
    "plot_errors(gd.w_, x_train, y_train, x_test, y_test, axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "\n",
    "While the repeated computation of the gradient vector in gradient descent might be as or even more expensive than the direct solution by solving the normal equations, it opens up an interesting venue for reducing the computational complexity. What if, instead of computing the exact gradient, we could obtain a reasonable approximation of the gradient by only looking at a few (random) data points?\n",
    "\n",
    "Specifically, let us define the approximated or **stochastic gradient** as\n",
    "\\begin{align*}\n",
    "\\tilde{\\nabla} E(\\mathbf{w}) &= \\nabla \\frac{1}{2b} \\sum_{n=n_1}^{n_b} (t_{n} - \\boldsymbol{\\phi}(\\mathbf{x}_n)\\cdot \\mathbf{w})^2\\\\\n",
    "&= \\frac{1}{b} \\tilde{\\boldsymbol{\\Phi}}^T(\\tilde{\\boldsymbol{\\Phi}}\\mathbf{w} - \\tilde{\\mathbf{t}})\n",
    "\\end{align*}\n",
    "where $n_1, \\dots, n_b$ are the indices of a bootstrap sample of the original dataset and $\\tilde{\\boldsymbol{\\Phi}}$ and $\\tilde{\\mathbf{t}}$ are the feature matrix and target vector resulting from that sample of indices. \n",
    "In thic context, the parameter $b$ is also called the **batch size**.\n",
    "With this definition, we can show relatively easily that the mean stochastic gradient is equal to the exact gradient, i.e., the expected value over all possible bootstrap samples satisfies:\n",
    "\\begin{equation*}\n",
    "\\mathbb{E}(\\tilde{\\nabla} E(\\mathbf{w})) = \\nabla E(\\mathbf{w}) \\enspace .\n",
    "\\end{equation*}\n",
    "\n",
    "Analysing the convergence (and working out a good termination condition) are now a bit more involved, but for the purpose of this activity, and really this unit, we can just keep working with the same framework as before."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E: Implement stochastic gradient descient\n",
    "\n",
    "**Finish the below implementation of stochastic gradient descent by adding code for drawing a bootstrap sample of prescribed batch size and computing the corresponding stochastic gradient. Hint: we have done something similar in the previous activity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLinearRegressor:\n",
    "\n",
    "    def __init__(self, batch_size=1, eta=0.01, tau_max=1000, epsilon=0.00001, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.tau_max = tau_max\n",
    "        self.epsilon = epsilon\n",
    "        self.random_state = random_state\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def fit(self, x, y):\n",
    "        RNG = np.random.default_rng(self.random_state)\n",
    "        n, p = x.shape\n",
    "        self.w_ = np.zeros(shape=(self.tau_max+1, p))\n",
    "        for tau in range(1, self.tau_max+1):\n",
    "            # YOUR CODE HERE\n",
    "            grad = # YOUR CODE HERE\n",
    "            self.w_[tau] = self.w_[tau-1] - self.eta*grad\n",
    "            if np.linalg.norm(self.w_[tau]-self.w_[tau-1]) < self.epsilon:\n",
    "                break\n",
    "        self.coef_ = self.w_[tau] \n",
    "        self.w_ = self.w_[:tau+1]\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        return x.dot(self.coef_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this implementation with the extreme batch size of just 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDLinearRegressor(batch_size=1).fit(x_train, y_train)\n",
    "sgd.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the computed weights are very close to the exactly computed weights, but let us investigate how we got there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "plot_weight_sequences(sgd.w_, direct.coef_, axs[0])\n",
    "plot_errors(sgd.w_, x_train, y_train, x_test, y_test, axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task F: Effect of Batch Size\n",
    "\n",
    "**Explain in one sentence how you expect the above picture to change for other (larger) batch sizes? Then test your hypothesis by completing the code below for running the experiment for a list of batch sizes.**\n",
    "\n",
    "*[YOUR ANSWER HERE]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 5, 10, len(x_train)]\n",
    "sgds = []\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, len(batch_sizes), figsize=(len(batch_sizes)*4, 4), tight_layout=True, sharey=True)\n",
    "for i, b in enumerate(batch_sizes):\n",
    "    plot_weight_sequences(sgds[i].w_, direct.coef_, axs[i])\n",
    "    axs[i].set_title(f'$b={b}$')\n",
    "    if i>0:\n",
    "        axs[i].get_legend().remove()\n",
    "        axs[i].set_ylabel(None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "#### Task G: Summarise what you have learned\n",
    "\n",
    "**Summarise again the ideas behind the three algorithms that we have implemented.**\n",
    "\n",
    "*[YOUR RESPONSE HERE]*\n",
    "\n",
    "We close with some further question that you might want to investigate independently:\n",
    "\n",
    "- With our first training sample of size 100 we already got very close to the optimal weights. Was this just luck or is there a high probability of this too happen? How many datapoints do we need on average to approximately reconstruct the true weight vector?\n",
    "- How does the learning rate affect the convergence rate of (stochastic) gradient descent? Do you believe having different learning rates at different iterations of the main learning loop can help? If it matters, is it better to have large values at start and smaller when close to finish or the other way around? You could validate your intuition using monotonically increasing or decreasing learning rates as functions of $\\tau$ (e.g. try $a/(b+\\tau)$ for different values of $a$ and $b$)\n",
    "- Could it happen with our current termination criterion that we stop stochastic gradient descent way too early with small badge sizes? Why and what could be a better criterion (and potentially weight update) that avoids this problem?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
